{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_file=r\"C:\\Users\\harya\\Desktop\\Edvancer\\Python\\Data\\Data\\SMSSpamCollection.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=pd.read_csv(data_file,delimiter='\\t',header=None,names=['target','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('english'))\n",
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message=message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words_sans_stop=[]\n",
    "    for word in words :\n",
    "        if word in stop:continue\n",
    "        words_sans_stop.append(word)\n",
    "    return [lemma.lemmatize(word) for word in words_sans_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_train,sd_test=train_test_split(sd,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer(analyzer=split_into_lemmas,min_df=20,max_df=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function split_into_lemmas at 0x0000025A4DAB9318>,\n",
       "                binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=3000, max_features=None,\n",
       "                min_df=20, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(sd_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=tfidf.transform(sd_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=tfidf.transform(sd_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data,sd_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97932328, 0.02067672]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test_data[6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ELLO BABE U OK?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sd_test['message'])[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Python pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn pipelines are composed of steps, each of which has to be some kind of transformer except the last step which can be a transformer or an estimator such as a machine learning model. A few eg of transformers is Normalizer, StandardScaler or the One Hot Encoder to name a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1=Pipeline(steps=[\n",
    "    ('tfidf',TfidfVectorizer(analyzer=split_into_lemmas,min_df=20,max_df=3000)),\n",
    "    ('classfier',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or you can also withe this way:\n",
    "pipe1=Pipeline([\n",
    "    ('tfidf',tfidf),\n",
    "    ('classifier',clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer=<function split_into_lemmas at 0x0000025A4DAB9318>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=3000, max_features=None,\n",
       "                                 min_df=20, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(sd_train['message'],sd_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95823681, 0.04176319],\n",
       "       [0.99030404, 0.00969596],\n",
       "       [0.99119974, 0.00880026],\n",
       "       ...,\n",
       "       [0.94020892, 0.05979108],\n",
       "       [0.97748664, 0.02251336],\n",
       "       [0.0141158 , 0.9858842 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.predict_proba(sd_test['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self,legs,arms):\n",
    "        self.legs = legs\n",
    "        self.arms = arms\n",
    "#        legs = 2\n",
    "#        arms = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "bob = Human(2,2)\n",
    "print(bob.legs)\n",
    "\n",
    "#bob is the object. Human is the class\n",
    "# A class is a blueprint or prototype that defines the variables and functions common to all objects,\n",
    "# technically encapsulated together\n",
    "# An objcet is a specimen of a class.\n",
    "# Eg: Car is a class, maruti 800 is an object\n",
    "\n",
    "#__init__ method is called constructot.\n",
    "# IT is called as soon as the memory for the object is allocated.\n",
    "# It sets attributes (or properties) on the object.\n",
    "# self keyword which refers to the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r'C:\\Users\\harya\\Desktop\\Edvancer\\Python\\Data\\Data\\Existing Base.csv'\n",
    "\n",
    "bd=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_NO</th>\n",
       "      <th>children</th>\n",
       "      <th>age_band</th>\n",
       "      <th>status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_partner</th>\n",
       "      <th>home_status</th>\n",
       "      <th>family_income</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>self_employed_partner</th>\n",
       "      <th>...</th>\n",
       "      <th>Investment Tax Saving Bond</th>\n",
       "      <th>Home Loan</th>\n",
       "      <th>Online Purchase Amount</th>\n",
       "      <th>Revenue Grid</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>Investment in Commudity</th>\n",
       "      <th>Investment in Equity</th>\n",
       "      <th>Investment in Derivative</th>\n",
       "      <th>Portfolio Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Zero</td>\n",
       "      <td>51-55</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Manual Worker</td>\n",
       "      <td>Secretarial/Admin</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;17,500, &gt;=15,000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Wales</td>\n",
       "      <td>74.67</td>\n",
       "      <td>18.66</td>\n",
       "      <td>32.32</td>\n",
       "      <td>89.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Zero</td>\n",
       "      <td>55-60</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;27,500, &gt;=25,000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>North West</td>\n",
       "      <td>20.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>22.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zero</td>\n",
       "      <td>26-30</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Other</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;30,000, &gt;=27,500</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>North</td>\n",
       "      <td>98.06</td>\n",
       "      <td>31.07</td>\n",
       "      <td>80.96</td>\n",
       "      <td>171.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Zero</td>\n",
       "      <td>18-21</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Manual Worker</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;15,000, &gt;=12,500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>4.10</td>\n",
       "      <td>14.15</td>\n",
       "      <td>17.57</td>\n",
       "      <td>-41.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Zero</td>\n",
       "      <td>45-50</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Business Manager</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;30,000, &gt;=27,500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.91</td>\n",
       "      <td>25.98</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>70.16</td>\n",
       "      <td>55.86</td>\n",
       "      <td>80.44</td>\n",
       "      <td>235.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REF_NO children age_band                status        occupation  \\\n",
       "0       1     Zero    51-55               Partner     Manual Worker   \n",
       "1       2     Zero    55-60  Single/Never Married           Retired   \n",
       "2       3     Zero    26-30  Single/Never Married      Professional   \n",
       "3       5     Zero    18-21  Single/Never Married      Professional   \n",
       "4       6     Zero    45-50               Partner  Business Manager   \n",
       "\n",
       "  occupation_partner home_status      family_income self_employed  \\\n",
       "0  Secretarial/Admin    Own Home  <17,500, >=15,000            No   \n",
       "1            Retired    Own Home  <27,500, >=25,000            No   \n",
       "2              Other    Own Home  <30,000, >=27,500           Yes   \n",
       "3      Manual Worker    Own Home  <15,000, >=12,500            No   \n",
       "4            Unknown    Own Home  <30,000, >=27,500            No   \n",
       "\n",
       "  self_employed_partner  ...  Investment Tax Saving Bond Home Loan  \\\n",
       "0                    No  ...                       19.99      0.00   \n",
       "1                    No  ...                        0.00      0.00   \n",
       "2                    No  ...                        0.00      3.49   \n",
       "3                    No  ...                        0.00      0.00   \n",
       "4                    No  ...                        0.00     45.91   \n",
       "\n",
       "  Online Purchase Amount Revenue Grid  gender         region  \\\n",
       "0                   0.00            1  Female          Wales   \n",
       "1                   0.00            2  Female     North West   \n",
       "2                   0.00            2    Male          North   \n",
       "3                   0.00            2  Female  West Midlands   \n",
       "4                  25.98            2  Female       Scotland   \n",
       "\n",
       "   Investment in Commudity  Investment in Equity  Investment in Derivative  \\\n",
       "0                    74.67                 18.66                     32.32   \n",
       "1                    20.19                  0.00                      4.33   \n",
       "2                    98.06                 31.07                     80.96   \n",
       "3                     4.10                 14.15                     17.57   \n",
       "4                    70.16                 55.86                     80.44   \n",
       "\n",
       "   Portfolio Balance  \n",
       "0              89.43  \n",
       "1              22.78  \n",
       "2             171.78  \n",
       "3             -41.70  \n",
       "4             235.02  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                             10155\n",
       "children                               5\n",
       "age_band                              13\n",
       "status                                 5\n",
       "occupation                             9\n",
       "occupation_partner                     9\n",
       "home_status                            5\n",
       "family_income                         13\n",
       "self_employed                          2\n",
       "self_employed_partner                  2\n",
       "year_last_moved                       95\n",
       "TVarea                                14\n",
       "post_code                          10040\n",
       "post_area                           2039\n",
       "Average Credit Card Transaction     1411\n",
       "Balance Transfer                    2183\n",
       "Term Deposit                        1419\n",
       "Life Insurance                      3111\n",
       "Medical Insurance                   1589\n",
       "Average A/C Balance                 2223\n",
       "Personal Loan                       1760\n",
       "Investment in Mutual Fund           2470\n",
       "Investment Tax Saving Bond           832\n",
       "Home Loan                            884\n",
       "Online Purchase Amount              1319\n",
       "Revenue Grid                           2\n",
       "gender                                 3\n",
       "region                                13\n",
       "Investment in Commudity             3558\n",
       "Investment in Equity                3250\n",
       "Investment in Derivative            3796\n",
       "Portfolio Balance                   8317\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                               int64\n",
       "children                            object\n",
       "age_band                            object\n",
       "status                              object\n",
       "occupation                          object\n",
       "occupation_partner                  object\n",
       "home_status                         object\n",
       "family_income                       object\n",
       "self_employed                       object\n",
       "self_employed_partner               object\n",
       "year_last_moved                      int64\n",
       "TVarea                              object\n",
       "post_code                           object\n",
       "post_area                           object\n",
       "Average Credit Card Transaction    float64\n",
       "Balance Transfer                   float64\n",
       "Term Deposit                       float64\n",
       "Life Insurance                     float64\n",
       "Medical Insurance                  float64\n",
       "Average A/C Balance                float64\n",
       "Personal Loan                      float64\n",
       "Investment in Mutual Fund          float64\n",
       "Investment Tax Saving Bond         float64\n",
       "Home Loan                          float64\n",
       "Online Purchase Amount             float64\n",
       "Revenue Grid                         int64\n",
       "gender                              object\n",
       "region                              object\n",
       "Investment in Commudity            float64\n",
       "Investment in Equity               float64\n",
       "Investment in Derivative           float64\n",
       "Portfolio Balance                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our custom transformer to be compatible with a scikit-learn pipeline it must be implemented as a class with methods such as fit, transorm, fit_transform, get_params, set_params. Instead of wititng all of those, we can simply just code the kind of transformation we want our transformer to apply and inherit everything else from some other class!\n",
    "\n",
    "Below classes are the steps in the pipeline. They need to have 3 functions in them- init, fit and transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will drop the columns whose names can be passed on the go\n",
    "class VarTypeSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,vartype,ignore_var):\n",
    "        self.vartype=vartype\n",
    "        self.ignore_var=ignore_var\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return X.select_dtypes(self.vartype).drop(self.ignore_var,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will create dummies with n-1 values, and will ignore the categories where the\n",
    "# count is less than some arbitrary value set by user.\n",
    "class get_dummies_PipeLineFriendly(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,freq_cutoff=0):\n",
    "        self.freq_cutoff=freq_cutoff\n",
    "        self.var_cat_dict={}\n",
    "        \n",
    "    def fit(self,x,y=None):\n",
    "        data_cols=x.columns\n",
    "        for col in data_cols:\n",
    "            k=x[col].value_counts()\n",
    "            cats=k.index[k>self.freq_cutoff][:-1]\n",
    "            self.var_cat_dict[col]=cats\n",
    "        return self\n",
    "            \n",
    "    def transform(self,x,y=None):\n",
    "        dummy_data=x.copy()\n",
    "        for col in self.var_cat_dict.keys():\n",
    "            for cat in self.var_cat_dict[col]:\n",
    "                name=col+'_'+cat\n",
    "                dummy_data[name]=(dummy_data[col]==cat).astype(int)\n",
    "            del dummy_data[col]\n",
    "        return dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline,FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train,bd_test=train_test_split(bd,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=bd_train.drop('Revenue Grid',axis=1)\n",
    "x_test=bd_test.drop('Revenue Grid',axis=1)\n",
    "y_train=bd_train['Revenue Grid']\n",
    "y_test=bd_test['Revenue Grid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                               int64\n",
       "children                            object\n",
       "age_band                            object\n",
       "status                              object\n",
       "occupation                          object\n",
       "occupation_partner                  object\n",
       "home_status                         object\n",
       "family_income                       object\n",
       "self_employed                       object\n",
       "self_employed_partner               object\n",
       "year_last_moved                      int64\n",
       "TVarea                              object\n",
       "post_code                           object\n",
       "post_area                           object\n",
       "Average Credit Card Transaction    float64\n",
       "Balance Transfer                   float64\n",
       "Term Deposit                       float64\n",
       "Life Insurance                     float64\n",
       "Medical Insurance                  float64\n",
       "Average A/C Balance                float64\n",
       "Personal Loan                      float64\n",
       "Investment in Mutual Fund          float64\n",
       "Investment Tax Saving Bond         float64\n",
       "Home Loan                          float64\n",
       "Online Purchase Amount             float64\n",
       "Revenue Grid                         int64\n",
       "gender                              object\n",
       "region                              object\n",
       "Investment in Commudity            float64\n",
       "Investment in Equity               float64\n",
       "Investment in Derivative           float64\n",
       "Portfolio Balance                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe=Pipeline([\n",
    "    ('cat_var',VarTypeSelector(['object'],ignore_var=['post_code','post_area'])),\n",
    "    ('dummies',get_dummies_PipeLineFriendly(100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FeatureUnion class combines two or more pipeline objects.\n",
    "# 1st pipeline is cat_pipe, 2nd is created in the combiner i.e. FeatureUnion itself\n",
    "\n",
    "pipe2=Pipeline([\n",
    "    ('features',FeatureUnion([\n",
    "        ('cat_pipe',cat_pipe),\n",
    "        ('num_var',VarTypeSelector(['int64','float64'],ignore_var=['REF_NO']))\n",
    "    ])),\n",
    "    ('clf',LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('features',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('cat_pipe',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('cat_var',\n",
       "                                                                  VarTypeSelector(ignore_var=['post_code',\n",
       "                                                                                              'post_area'],\n",
       "                                                                                  vartype=['object'])),\n",
       "                                                                 ('dummies',\n",
       "                                                                  get_dummies_PipeLineFriendly(freq_cutoff=100))],\n",
       "                                                          verbose=False)),\n",
       "                                                ('num_var',\n",
       "                                                 VarTypeSelector(ignore_var=['REF_NO'],\n",
       "                                                                 vartype=['int64',\n",
       "                                                                          'float64']))],\n",
       "                              transformer_weights=None, verbose=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the fir method for the feature union object pushes the data down \n",
    "# the piplines separately and then results are combined and returned.\n",
    "\n",
    "pipe2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00352334, 0.99647666],\n",
       "       [0.00623159, 0.99376841],\n",
       "       [0.00768033, 0.99231967],\n",
       "       ...,\n",
       "       [0.43372072, 0.56627928],\n",
       "       [0.17600561, 0.82399439],\n",
       "       [0.01433096, 0.98566904]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save python objects to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harya\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model_pipeline.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe1,'my_model_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harya\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message=message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words_sans_stop=[]\n",
    "    for word in words :\n",
    "        if word in stop:continue\n",
    "        words_sans_stop.append(word)\n",
    "    return [lemma.lemmatize(word) for word in words_sans_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel=open('my_model_pipeline.pkl','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=joblib.load(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_msg=['I‘m going to try for 2 months ha ha only joking',\n",
    "        '''Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. \n",
    "        Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's''']\n",
    "my_df=pd.DataFrame({'message':my_msg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0    I‘m going to try for 2 months ha ha only joking\n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95929988, 0.04070012],\n",
       "       [0.01743449, 0.98256551]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba(my_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
